{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.vectorizer import BidirectionalLM\n",
    "from modules.elmo_data import CustomIterableDataset, load_token_dict, make_batch as make_batch_init\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "token_dict = load_token_dict('../../fast_data/Elmo-taiga/vocab.txt')\n",
    "make_batch = partial(make_batch_init, token_dict=token_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'num_layers': 2, \n",
    "    'hidden_size': 2048,\n",
    "    'sru_attn_proj_size': 1024,\n",
    "    'attention_last_n_layers': 0\n",
    "}\n",
    "\n",
    "vectorizer = BidirectionalLM(\n",
    "    vocab_size=len(token_dict), \n",
    "    model_params=model_params, \n",
    "    learning_rate=0.001, \n",
    "    cutoffs=[10_000, 50_000],\n",
    "    elmo_options_file='../Elmo-taiga/options.json', \n",
    "    elmo_weight_file='../Elmo-taiga/model.hdf5',\n",
    ")\n",
    "\n",
    "for param in vectorizer.parameters():\n",
    "    param.requires_grad = True\n",
    "    torch.nn.init.normal_(param, std=1e-10)    \n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующий шаг: конструируем загрузку данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/media/fast_data/anaconda/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /media/fast_data/ELMO-SRU/elmo_lstm_2lrs_checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                       | Params\n",
      "-------------------------------------------------------------\n",
      "0 | bilstm        | _ElmoBiLm                  | 129 M \n",
      "1 | forward_loss  | AdaptiveLogSoftmaxWithLoss | 16.7 M\n",
      "2 | backward_loss | AdaptiveLogSoftmaxWithLoss | 16.7 M\n",
      "-------------------------------------------------------------\n",
      "162 M     Trainable params\n",
      "0         Non-trainable params\n",
      "162 M     Total params\n",
      "650.798   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc889f854752475db3af01523cbf6cc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "dataset = CustomIterableDataset('joined_news_long_texts_udpipe_8796201_293713268.txt')\n",
    "train_dataloader = DataLoader(\n",
    "    dataset, batch_size=BATCH_SIZE,\n",
    "    shuffle=False, num_workers=24, pin_memory=True, \n",
    "    collate_fn=make_batch\n",
    ")\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(dirpath=\"elmo_lstm_2lrs_checkpoints\", save_top_k=-1)\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "trainer = pl.Trainer(\n",
    "    gradient_clip_val=1.5, \n",
    "    max_epochs=1, \n",
    "    callbacks=[\n",
    "        pl.callbacks.TQDMProgressBar(refresh_rate=100), \n",
    "        checkpoint_callback\n",
    "    ],\n",
    "    limit_train_batches=549763 // 60\n",
    "    # limit_train_batches=1\n",
    "    # precision=16   \n",
    ")\n",
    "            \n",
    "vectorizer.fit(vectorizer, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f64ecb9d900>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# h = np.array(model.history[1000:])\n",
    "h = np.array(vectorizer.history)\n",
    "eps = 0.001\n",
    "hh = [h[0]]\n",
    "for v in h[1:]:\n",
    "    hh.append(hh[-1] * (1-eps) + v * eps)\n",
    "    \n",
    "plt.plot(hh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * * \n",
    "# NER Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.ner_tasks import RUSSIAN\n",
    "from modules.ner_data import get_dataloaders\n",
    "\n",
    "ner_task = RUSSIAN['WikiNeural']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, val_dataloader, test_dataloader = get_dataloaders(\n",
    "    ner_task,\n",
    "    batch_size=128,\n",
    "    num_workers=24,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "module CRFModel not in sys.modules",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCRFModel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/fast_data/anaconda/lib/python3.10/importlib/__init__.py:148\u001b[0m, in \u001b[0;36mreload\u001b[0;34m(module)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mget(name) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m module:\n\u001b[1;32m    147\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m not in sys.modules\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 148\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(name), name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m _RELOADING:\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _RELOADING[name]\n",
      "\u001b[0;31mImportError\u001b[0m: module CRFModel not in sys.modules"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(CRFModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type            | Params\n",
      "-----------------------------------------------\n",
      "0 | vectorizer | BidirectionalLM | 162 M \n",
      "1 | lstm       | LSTM            | 1.4 M \n",
      "2 | relu       | ReLU            | 0     \n",
      "3 | line       | Linear          | 2.2 K \n",
      "4 | crf        | CRF             | 99    \n",
      "-----------------------------------------------\n",
      "1.4 M     Trainable params\n",
      "162 M     Non-trainable params\n",
      "164 M     Total params\n",
      "656.598   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b0b2a1e3621457bad94f253ab9e974b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 18\u001b[0m\n\u001b[1;32m      5\u001b[0m ner_model \u001b[38;5;241m=\u001b[39m CRFModel(\n\u001b[1;32m      6\u001b[0m     ner_labels\u001b[38;5;241m=\u001b[39mner_task[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels_vocab\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m      7\u001b[0m     vectorizer\u001b[38;5;241m=\u001b[39mvectorizer, \n\u001b[1;32m      8\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \n\u001b[1;32m      9\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m     13\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     14\u001b[0m     gradient_clip_val\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10.5\u001b[39m, \n\u001b[1;32m     15\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, \n\u001b[1;32m     16\u001b[0m )\n\u001b[0;32m---> 18\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mner_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/fast_data/anaconda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:520\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    518\u001b[0m model \u001b[38;5;241m=\u001b[39m _maybe_unwrap_optimized(model)\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m--> 520\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/fast_data/anaconda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m/media/fast_data/anaconda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:559\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_connector\u001b[38;5;241m.\u001b[39mattach_data(\n\u001b[1;32m    550\u001b[0m     model, train_dataloaders\u001b[38;5;241m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[38;5;241m=\u001b[39mval_dataloaders, datamodule\u001b[38;5;241m=\u001b[39mdatamodule\n\u001b[1;32m    551\u001b[0m )\n\u001b[1;32m    553\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    555\u001b[0m     ckpt_path,\n\u001b[1;32m    556\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    557\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    558\u001b[0m )\n\u001b[0;32m--> 559\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/media/fast_data/anaconda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:935\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    932\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 935\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    940\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/media/fast_data/anaconda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:978\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    976\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m--> 978\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    979\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/media/fast_data/anaconda/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:201\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/media/fast_data/anaconda/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:354\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher\u001b[38;5;241m.\u001b[39msetup(combined_loader)\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 354\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/fast_data/anaconda/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:133\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 133\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/media/fast_data/anaconda/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:218\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[0;32m--> 218\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    220\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanual_optimization\u001b[38;5;241m.\u001b[39mrun(kwargs)\n",
      "File \u001b[0;32m/media/fast_data/anaconda/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:185\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[0;34m(self, optimizer, kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m         closure()\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_idx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/media/fast_data/anaconda/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:261\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_ready()\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_completed()\n",
      "File \u001b[0;32m/media/fast_data/anaconda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:142\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m hook_name\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    145\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m/media/fast_data/anaconda/lib/python3.10/site-packages/pytorch_lightning/core/module.py:1265\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimizer_step\u001b[39m(\n\u001b[1;32m   1227\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1228\u001b[0m     epoch: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1231\u001b[0m     optimizer_closure: Optional[Callable[[], Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1232\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1233\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;124;03m    Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[1;32m   1235\u001b[0m \u001b[38;5;124;03m    the optimizer.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;124;03m                    pg[\"lr\"] = lr_scale * self.learning_rate\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1265\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/fast_data/anaconda/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py:158\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "File \u001b[0;32m/media/fast_data/anaconda/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:224\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;66;03m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[0;32m--> 224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/fast_data/anaconda/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py:114\u001b[0m, in \u001b[0;36mPrecisionPlugin.optimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[39;00m\n\u001b[1;32m    113\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/fast_data/anaconda/lib/python3.10/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/media/fast_data/anaconda/lib/python3.10/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m/media/fast_data/anaconda/lib/python3.10/site-packages/torch/optim/adam.py:121\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 121\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m    124\u001b[0m     params_with_grad \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/media/fast_data/anaconda/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py:101\u001b[0m, in \u001b[0;36mPrecisionPlugin._wrap_closure\u001b[0;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap_closure\u001b[39m(\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     91\u001b[0m     model: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     92\u001b[0m     optimizer: Optimizer,\n\u001b[1;32m     93\u001b[0m     closure: Callable[[], Any],\n\u001b[1;32m     94\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     95\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m    ``on_before_optimizer_step`` hook is called.\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m    The closure (generally) runs ``backward`` so this allows inspecting gradients in this hook. This structure is\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    consistent with the ``PrecisionPlugin`` subclasses that cannot pass ``optimizer.step(closure)`` directly.\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m     closure_result \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_closure(model, optimizer)\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m closure_result\n",
      "File \u001b[0;32m/media/fast_data/anaconda/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:140\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[0;32m/media/fast_data/anaconda/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:126\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ClosureResult:\n\u001b[0;32m--> 126\u001b[0m     step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarning_cache\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`training_step` returned `None`. If this was on purpose, ignore this warning...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/media/fast_data/anaconda/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:308\u001b[0m, in \u001b[0;36m_AutomaticOptimization._training_step\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# manually capture logged metrics\u001b[39;00m\n\u001b[0;32m--> 308\u001b[0m training_step_output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mpost_training_step()\n\u001b[1;32m    311\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_result_cls\u001b[38;5;241m.\u001b[39mfrom_training_step_output(training_step_output, trainer\u001b[38;5;241m.\u001b[39maccumulate_grad_batches)\n",
      "File \u001b[0;32m/media/fast_data/anaconda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:288\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 288\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    291\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m/media/fast_data/anaconda/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:366\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mtrain_step_context():\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, TrainingStep)\n\u001b[0;32m--> 366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/fast_data/ELMO-SRU/modules/crf_model.py:45\u001b[0m, in \u001b[0;36mCRFModel.training_step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     42\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorizer\u001b[38;5;241m.\u001b[39mvectorize(batch)\n\u001b[1;32m     44\u001b[0m transformed \u001b[38;5;241m=\u001b[39m embeddings\n\u001b[0;32m---> 45\u001b[0m transformed, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m transformed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(transformed)\n\u001b[1;32m     47\u001b[0m transformed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mline(transformed)\n",
      "File \u001b[0;32m/media/fast_data/anaconda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/media/fast_data/anaconda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:773\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     batch_sizes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 773\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLSTM: Expected input to be 2-D or 3-D but received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-D tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    774\u001b[0m     is_batched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m    775\u001b[0m     batch_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "from modules.crf_model import CRFModel\n",
    "\n",
    "vectorizer.emb_size=1024\n",
    "\n",
    "ner_model = CRFModel(\n",
    "    ner_labels=ner_task['labels_vocab'], \n",
    "    vectorizer=vectorizer, \n",
    "    weight_decay=0, \n",
    "    learning_rate=1e-3\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator='gpu', \n",
    "    gradient_clip_val=10.5, \n",
    "    max_epochs=5, \n",
    ")\n",
    "\n",
    "trainer.fit(ner_model, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.validate(ner_model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
